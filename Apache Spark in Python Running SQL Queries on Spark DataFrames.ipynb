{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Spark with Python: Running SQL Queries on Spark DataFrames\n",
    "\n",
    "This notebook is designed to introduce some basic concepts and help get you familiar with using Spark in Python.\n",
    "\n",
    "In this notebook, we will load and explore the titanic dataset. Specifically, this tutorial covers:\n",
    "\n",
    "  - Loading data in memory\n",
    "  - Creating SQLContext\n",
    "  - Creating Spark DataFrame\n",
    "  - Group data by columns\n",
    "  - Operating on columns\n",
    "  - Running SQL Queries from a Spark DataFrame\n",
    "\n",
    "##### by John Ryan using IBM Data Science Workbench."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First, we import some Python packages that we need:\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.param import Param, Params\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/resources/data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the first four rows of the pandas dataframe \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre- processing: Missing Value Inputation**\n",
    "\n",
    "Counting and filling the missing values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Munging\n",
    "#Checking for missing values in the data\n",
    "data.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C23 C25 C27        4\n",
       "G6                 4\n",
       "B96 B98            4\n",
       "D                  3\n",
       "C22 C26            3\n",
       "E101               3\n",
       "F2                 3\n",
       "F33                3\n",
       "B57 B59 B63 B66    2\n",
       "C68                2\n",
       "B58 B60            2\n",
       "E121               2\n",
       "D20                2\n",
       "E8                 2\n",
       "E44                2\n",
       "B77                2\n",
       "C65                2\n",
       "D26                2\n",
       "E24                2\n",
       "E25                2\n",
       "B20                2\n",
       "C93                2\n",
       "D33                2\n",
       "E67                2\n",
       "D35                2\n",
       "D36                2\n",
       "C52                2\n",
       "F4                 2\n",
       "C125               2\n",
       "C124               2\n",
       "                  ..\n",
       "F G63              1\n",
       "A6                 1\n",
       "D45                1\n",
       "D6                 1\n",
       "D56                1\n",
       "C101               1\n",
       "C54                1\n",
       "D28                1\n",
       "D37                1\n",
       "B102               1\n",
       "D30                1\n",
       "E17                1\n",
       "E58                1\n",
       "F E69              1\n",
       "D10 D12            1\n",
       "E50                1\n",
       "A14                1\n",
       "C91                1\n",
       "A16                1\n",
       "B38                1\n",
       "B39                1\n",
       "C95                1\n",
       "B78                1\n",
       "B79                1\n",
       "C99                1\n",
       "B37                1\n",
       "A19                1\n",
       "E12                1\n",
       "A7                 1\n",
       "D15                1\n",
       "Name: Cabin, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display of the total Education value counts\n",
    "data['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fill in the NaN values with the most common cabin type in the data\n",
    "data['Cabin'].fillna('G6',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display of the total Embarked value counts\n",
    "data['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in the NaN values with the most common Embarked type in the data\n",
    "data['Embarked'].fillna('s',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.00    30\n",
       "22.00    27\n",
       "18.00    26\n",
       "30.00    25\n",
       "28.00    25\n",
       "19.00    25\n",
       "21.00    24\n",
       "25.00    23\n",
       "36.00    22\n",
       "29.00    20\n",
       "32.00    18\n",
       "27.00    18\n",
       "35.00    18\n",
       "26.00    18\n",
       "16.00    17\n",
       "31.00    17\n",
       "23.00    15\n",
       "34.00    15\n",
       "33.00    15\n",
       "20.00    15\n",
       "39.00    14\n",
       "17.00    13\n",
       "40.00    13\n",
       "42.00    13\n",
       "45.00    12\n",
       "38.00    11\n",
       "50.00    10\n",
       "2.00     10\n",
       "4.00     10\n",
       "47.00     9\n",
       "         ..\n",
       "28.50     2\n",
       "40.50     2\n",
       "63.00     2\n",
       "13.00     2\n",
       "10.00     2\n",
       "45.50     2\n",
       "70.00     2\n",
       "30.50     2\n",
       "71.00     2\n",
       "59.00     2\n",
       "57.00     2\n",
       "55.00     2\n",
       "0.75      2\n",
       "64.00     2\n",
       "23.50     1\n",
       "14.50     1\n",
       "0.67      1\n",
       "53.00     1\n",
       "0.92      1\n",
       "0.42      1\n",
       "70.50     1\n",
       "36.50     1\n",
       "80.00     1\n",
       "66.00     1\n",
       "74.00     1\n",
       "12.00     1\n",
       "55.50     1\n",
       "34.50     1\n",
       "24.50     1\n",
       "20.50     1\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display of the total Age value counts\n",
    "data['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      22.0\n",
       "1      38.0\n",
       "2      26.0\n",
       "3      35.0\n",
       "4      35.0\n",
       "5      24.0\n",
       "6      54.0\n",
       "7       2.0\n",
       "8      27.0\n",
       "9      14.0\n",
       "10      4.0\n",
       "11     58.0\n",
       "12     20.0\n",
       "13     39.0\n",
       "14     14.0\n",
       "15     55.0\n",
       "16      2.0\n",
       "17     24.0\n",
       "18     31.0\n",
       "19     24.0\n",
       "20     35.0\n",
       "21     34.0\n",
       "22     15.0\n",
       "23     28.0\n",
       "24      8.0\n",
       "25     38.0\n",
       "26     24.0\n",
       "27     19.0\n",
       "28     24.0\n",
       "29     24.0\n",
       "       ... \n",
       "861    21.0\n",
       "862    48.0\n",
       "863    24.0\n",
       "864    24.0\n",
       "865    42.0\n",
       "866    27.0\n",
       "867    31.0\n",
       "868    24.0\n",
       "869     4.0\n",
       "870    26.0\n",
       "871    47.0\n",
       "872    33.0\n",
       "873    47.0\n",
       "874    28.0\n",
       "875    15.0\n",
       "876    20.0\n",
       "877    19.0\n",
       "878    24.0\n",
       "879    56.0\n",
       "880    25.0\n",
       "881    33.0\n",
       "882    22.0\n",
       "883    28.0\n",
       "884    25.0\n",
       "885    39.0\n",
       "886    27.0\n",
       "887    19.0\n",
       "888    24.0\n",
       "889    26.0\n",
       "890    32.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Age'].fillna(24.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fill missing values with the mean\n",
    "data = data.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for missing values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values in the data\n",
    "data.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Create a Spark DataFrame\n",
    " \n",
    " In order to work with Spark Data Frames we need to initialize SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the spark SQL Context is created using SQLContext(sc)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: long (nullable = true)\n",
      " |-- Survived: long (nullable = true)\n",
      " |-- Pclass: long (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: long (nullable = true)\n",
      " |-- Parch: long (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#With the combination of the SQLContext and the pandas dataframe we can now create the \n",
    "#spark dataframe\n",
    "sdata = sqlContext.createDataFrame(data)\n",
    "sdata.printSchema()#prints out the data schema for the new data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Selecting Data Columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------+\n",
      "|   Fare|          Ticket|Survived|\n",
      "+-------+----------------+--------+\n",
      "|   7.25|       A/5 21171|       0|\n",
      "|71.2833|        PC 17599|       1|\n",
      "|  7.925|STON/O2. 3101282|       1|\n",
      "|   53.1|          113803|       1|\n",
      "|   8.05|          373450|       0|\n",
      "| 8.4583|          330877|       0|\n",
      "|51.8625|           17463|       0|\n",
      "| 21.075|          349909|       0|\n",
      "|11.1333|          347742|       1|\n",
      "|30.0708|          237736|       1|\n",
      "|   16.7|         PP 9549|       1|\n",
      "|  26.55|          113783|       1|\n",
      "|   8.05|       A/5. 2151|       0|\n",
      "| 31.275|          347082|       0|\n",
      "| 7.8542|          350406|       0|\n",
      "|   16.0|          248706|       1|\n",
      "| 29.125|          382652|       0|\n",
      "|   13.0|          244373|       1|\n",
      "|   18.0|          345763|       0|\n",
      "|  7.225|            2649|       1|\n",
      "+-------+----------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Taking a look at some of the columns\n",
    "sdata.select('Fare','Ticket', 'Survived').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Grouping by and Aggregation__\n",
    "\n",
    "When using the sql group by command we can dig further into the data and group all titanic survivers and non survivers by the average fair paid.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|Survived|        avg(Fare)|\n",
      "+--------+-----------------+\n",
      "|       0| 22.1178868852459|\n",
      "|       1|48.39540760233918|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grouping by survivor column and aggregating the fare column to return the average fare.\n",
    "sdata.groupby(['Survived'])\\\n",
    ".agg({\"Fare\": \"AVG\"})\\\n",
    ".show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|Survived|count(Fare)|\n",
      "+--------+-----------+\n",
      "|       1|        342|\n",
      "|       0|        549|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using sql group by command we can dig further into the data to aggregate and sort. \n",
    "sdata.groupby(['Survived'])\\\n",
    ".agg({\"Fare\": \"count\"})\\\n",
    ".sort(\"count(Fare)\", ascending=True)\\\n",
    ".show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SQL Queries using Spark__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 1 convert spark dataframe to a table\n",
    "sdata.registerTempTable(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|          Ticket|\n",
      "+----------------+\n",
      "|       A/5 21171|\n",
      "|        PC 17599|\n",
      "|STON/O2. 3101282|\n",
      "|          113803|\n",
      "|          373450|\n",
      "|          330877|\n",
      "|           17463|\n",
      "|          349909|\n",
      "|          347742|\n",
      "|          237736|\n",
      "|         PP 9549|\n",
      "|          113783|\n",
      "|       A/5. 2151|\n",
      "|          347082|\n",
      "|          350406|\n",
      "|          248706|\n",
      "|          382652|\n",
      "|          244373|\n",
      "|          345763|\n",
      "|            2649|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use the SQL method part of SQLcontext to query the table\n",
    "query1 = sqlContext.sql(\"SELECT Ticket FROM titanic WHERE Fare < 1000\")\n",
    "query1.show()"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Apache Spark in Python Running SQL Queries on Spark DataFrames.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
